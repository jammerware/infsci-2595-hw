---
title: "INFSCI 2595 Final"
subtitle: "Part iA: Predictors (Lexicon: SentimentR)"
author: "Ben Stein"
date: "4/27/2022"
output: html_document
knit: (function(inputFile, encoding) {
  rmarkdown::render(inputFile, encoding = encoding, output_dir = "knit") }
  )
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# About this document

In this document, I perform exploratory data analysis on the variables from the SentimentR lexicon data.

# Setup

## Libraries and tools

```{r}
library(tidyverse)
source("./tools.R")
```

## Data

```{r}
df <- load_project_data() %>%
  select(response_log, outcome_numeric, starts_with("xs"))

df %>% glimpse
```

# Distributions

Let's look at the distributions of the variables first.

```{r}
df %>% 
  select(-outcome_numeric, -response_log) %>%
  summary
```

Somewhat unlike other groups of sentiment variables, the scales of these inputs are less different. Nevertheless, I'll probably center and scale them, because I'm not sure if you ever _don't_ want to do that.

```{r}
visualize_distributions(df, "xs")
```

In this predictor group, some of the distributions are noticeably less normal (e.g. inputs 4 and 5, which seem right-tailed).

## Distinct values

As I worked with each group of continuous predictors, I noticed that some seem to have more unique values than others. Let's quantify that:

```{r}
df %>%
  select(-outcome_numeric, -response_log) %>%
  pivot_longer(cols = everything()) %>%
  group_by(name) %>% 
  unique %>%
  count
```

In this group, variables have very similar numbers of total distinct values, so it's hard to infer whether one encodes more knowledge about the response/outcome than the others.

# Correlation within the group

Let's see if any of these inputs are correlated with one another or with the response variable.

```{r}
visualize_correlations(df, "xs")
```

We can observe significant correlation between the predictors here - in particular, inputs 5 and 6 seem highly correlated with a few other inputs. Thus, they're probably good candidates to exclude in refined modeling.

# Relationship to target variables

## The continuous `response` variable

Note that I log-transformed response since that's what I'll be predicting anyway.

```{r}
df %>%
  pivot_longer(cols = starts_with("xs")) %>%
  ggplot(mapping = aes(x = value, y = response_log)) +
  geom_point() +
  geom_smooth(formula = y ~ x, method = "loess") + 
  facet_wrap(~ name, scales = "free")
```

Like the other lexicons, the loess lines are nearly (but not exactly) linear. Based on this figure and the corresponding ones for other groups, I'm interested in using splines to model them.

## The `outcome` classification target

```{r}
df %>%
  select(-response_log) %>%
  pivot_longer(cols = starts_with("xs")) %>%
  ggplot(mapping = aes(x = value, y = outcome_numeric)) +
  geom_point(size = 4, alpha = .33) +
  facet_wrap(~ name, scales = "free")
```

What I take from this is that this group is not as useful for predicting `outcome` as some of the other sentiment-based predictor groups, as there is not a clear trend between values of each predictor and the outcome.