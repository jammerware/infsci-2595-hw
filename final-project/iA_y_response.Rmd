---
title: "INFSCI 2595 Final"
subtitle: "Part iA: Prediction targets (`response`)"
author: "Ben Stein"
date: "4/27/2022"
output: html_document
knit: (function(inputFile, encoding) {
    rmarkdown::render(inputFile, encoding = encoding, output_dir = "knit") }
  )
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# About this document

In this document, I perform exploratory data analysis on the `response` variable, which is our prediction target for the linear regression portions of the project.

# Setup

## Libraries and tools

```{r}
library(tidyverse)

source("./tools.R")
```

## Data

```{r}
df <- load_project_data(convert_categoricals = FALSE, response_to_log = FALSE) %>%
  select(-outcome_numeric)
df %>% glimpse()
```

# Exploratory Data Analysis

The `response` variable is continuous and describes the number of hours per week are associated with a product being sold to a customer. 

## The variable itself

Let's start with its distribution:

```{r}
df %>%
  ggplot(mapping = aes(x = response)) +
  geom_histogram(bins = 50)
```

We can see that the variable is heavily right-tailed. We can understand this quantitatively by looking at summary distribution statistics.

```{r}
df %>%
  select(response) %>%
  summary()
```

This suggests that (independent of the assignment requirements), we probably want to log-transform the variable when modeling. 

```{r}
df %>%
  ggplot(mapping = aes(x = log(response))) +
  geom_histogram(bins = 50)
```

After log transformation, we can see that the distribution appears more normal. Let's add the log-transformed response to the dataframe for the rest of our analysis (since that's what we'll be predicting anyway):

```{r}
df <- df %>%
  mutate(log_response = log(response))
```


## In relation to categorical predictors

Let's examine how `response`'s distribution looks when faceted by our categorical variables `region` and `customer`. 

### Region

```{r}
df %>%
  select(region, log_response) %>%
  ggplot(mapping = aes(x = log_response)) + 
  geom_histogram(bins = 50) +
  facet_wrap(~region, scales = "free") + 
  theme_bw() +
  theme(axis.text.y = element_blank())
```

These distributions don't seem to vary widely by region. It may be worth noting that region `XX`'s distribution is a little more "ragged" than the other two. Let's move onto `customer`.

### Customer

```{r}
df %>%
  select(customer, log_response) %>%
  ggplot(mapping = aes(x = log_response)) + 
  geom_histogram(bins = 50) +
  facet_wrap(~customer, scales = "free") + 
  theme_bw() +
  theme(axis.text.y = element_blank())
```

The thing I notice here most is that the `Other` customer group appears the most Gaussian after log transformation. Combined with the fact that `Other` is the most populous group (as shown in previous portions of the analysis) my inference is that the "true" distribution can be approximated with a Gaussian.

### Both categorical predictors

```{r}
df %>%
  select(customer, region, log_response) %>%
  ggplot(mapping = aes(x = log_response)) + 
  geom_histogram(bins = 50) +
  facet_grid(region ~ customer, scales = "free") + 
  theme_bw() +
  theme(axis.text.y = element_blank())
```

This is one of those figures that I don't really know what to do with. The only trend I see is that combinations of regions and customers with small numbers of observations have distributions that are difficult to interpret (which doesn't surprise me anyway). Again we see that combinations with high numbers of observations are roughly Gaussian in distribution (after log transformation).

## In relation to continuous predictors

Let's now visualize how `response` correlates with the continuous predictors from each group.

### Lexicon: AFINN

```{r}
visualize_correlations(df, "xa")
```

Of the NRC lexicon variables, only `xa_01` and `xa_02` seem moderately correlated with `log_response`. It's important to notice that some of these predictors are also highly correlated with each other (e.g. `xa_04` is correlated with `xa_07` and `xa_08`, and with `xa_05` to a lesser extent.)

# TODO: focus this on relationship to the outcome?
