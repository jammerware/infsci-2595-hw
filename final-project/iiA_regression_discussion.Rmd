---
title: "Part iiA: Regression models (Discussion)"
subtitle: "INFSCI 2595 Final"
author: "Ben Stein"
date: "4/27/2022"
output: html_document
knit: (function(inputFile, encoding) {
  rmarkdown::render(inputFile, encoding = encoding, output_dir = "knit") }
  )
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# About this document

In this document, I review the coefficient summaries from the top 3 regression models identified in the previous section and compare them to identify the most important inputs.

# Setup (libraries and tools)

## Libraries and tools

```{r}
library(tidyverse)
library(caret)

source("./tools.R")
```

## Models

```{r}
lm_model5 <- readr::read_rds("./models/lm_rank1_model5.rds")
lm_model4 <- readr::read_rds("./models/lm_rank2_model4.rds")
lm_model6 <- readr::read_rds("./models/lm_rank3_model6.rds")
```

# Coefficient summaries

```{r}
get_varimp <- function(model) {
  model %>%
    varImp %>%
    arrange(desc(Overall)) %>%
    head(15) %>%
    rownames_to_column() %>%
    rename(
      predictor = rowname,
      importance = Overall
    )
}

plot_lm_varimp <- function(model) {
  get_varimp(model) %>%
    ggplot(mapping = aes(x = importance, y = factor(predictor, level = predictor))) +
    geom_col()
}
```


## Best-ranked model (model 5)

```{r}
plot_lm_varimp(lm_model5)
```

A feature from the `xb_07` lexicon shows up multiple times in the top performers from this model, suggesting that it's important. `customer` is also a variable of interest based on this figure.

Predictors which show up more than once in the top 15:

- customer (14)
- xa_08 (3)
- xb_07 (3, once by itself)
- xn_08 (2)
- xs_04 (2)
- xs_05 (2)

## Second-best ranked model (model 4)

```{r}
plot_lm_varimp(lm_model4)
```

Predictors which show up more than once in the top 15:

- region (8, once by itself)
- xb_02 (2, once by itself)
- xb_04 (2, once by itself)
- xb_07 (2, once by itself)
- xn_04 (2, once by itself)
- xn_08 (2, once by itself)
- xs_03 (2, once by itself)

Predictors which show up multiple times in both this and the previous model:
- xb_07
- xn_08

## Third-best model ranked model (model 6)

```{r}
plot_lm_varimp(lm_model6)
```

Predictors which show up more than once in the top 15:

- xb_01 (4)
- xb_04 (2)
- xb_05 (3)
- xb_06 (3)
- xb_07 (2)
- xn_07 (2)
- xn_08 (2)
- xs_06 (2)

Predictors which show up multiple times in both this and _both_ the previous models:
- xb_07
- xn_08

Additionally, in this model (but less so the others), features from the Bing lexicon seem dominant.

# Discussion

## The importance of region and customer

Region only appears in one of these models (model 4), but it dominates other predictors by a lot. This makes me think region is a useful predictor. It's also interesting that while interactions between region and the sentiment features does matter, `region` by itself shows up twice in the top 15 features.

It's harder to make sense of the `customer` predictor in model 5. Unlike region, it doesn't seem important by itself, but does when interacted with some sentiment features. However, it's hard to tell how important it really is. For example, what's the median variable importance in this model?

```{r}
lm_model5 %>% 
  varImp %>%
  pull(Overall) %>%
  median
```

The fact that the median importance is much lower than the variables in the top 15 makes it clear that these variables matter, but I don't know how to make sense of the specific interactions we're observing.

## Sentiment predictors

### The dominance of the Bing lexicon

variables derived from the Bing lexicon seem to show up more than other sentiment groups, suggesting that, for whatever reason, that lexicon is most suitable for our current application.

### Recurring top performers

`xb_07` and `xn_08` showed up in the top 3 models, so I'll take a closer look at them in section `iiC` which conducts predictions to examine the effects of these variables on the mean trend.

# Bonus (fail): Visualizing common coefficients

I had a try at visualizing the common coefficients across models. However, this isn't totally accurate, because it considers interactions of, for example `xn_03` as distinct from `xn_03` as a solo predictor. I left it in because it was a lot of work.

```{r}
importance_to_df <- function(model, model_name) {
  varImp(model) %>%
    arrange(desc(Overall)) %>%
    mutate(model = model_name) %>%
    rownames_to_column() %>%
    rename(importance = Overall, predictor = rowname) %>%
    head(15)
}

df_importance <- rbind(
  importance_to_df(lm_model5, "model5"),
  importance_to_df(lm_model4, "model4"),
  importance_to_df(lm_model6, "model6")
)

df_importance %>%
  ggplot(mapping = aes(x = importance, y = predictor, fill = model)) + 
  geom_bar(stat="identity", position = position_dodge2(preserve = "single"))
```

