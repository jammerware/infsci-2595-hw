---
title: "INFSCI 2595 Final"
subtitle: "Part Ia: Predictors (Lexicon: NRC)"
author: "Ben Stein"
date: "4/27/2022"
output: html_document
knit: (function(inputFile, encoding) {
  rmarkdown::render(inputFile, encoding = encoding, output_dir = "knit") }
  )
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# About this document

In this document, I perform exploratory data analysis on the variables from the NRC lexicon data.

# Setup

## Libraries and tools

```{r}
library(tidyverse)
source("./tools.R")
```

## Data

```{r}
df <- load_project_data() %>%
  select(response_log, outcome_numeric, starts_with("xn"))

df %>% glimpse
```

# Distributions

Let's look at the distributions of the variables first.

```{r}
df %>% 
  select(starts_with("xn")) %>%
  summary
```

Like other groups of sentiment variables, these inputs have differing scales and will thus need preprocessing.

```{r}
visualize_distributions(df, "xn")
```

As we've probably come to expect, these variables have approximately normal distribution, especially the lower-numbered ones.

## Distinct values

As I worked with each group of continuous predictors, I noticed that some seem to have more unique values than others. Let's quantify that:

```{r}
df %>%
  select(starts_with("xn")) %>%
  pivot_longer(cols = everything()) %>%
  group_by(name) %>% 
  unique %>%
  count
```

As we can see, some inputs have high ranges of values, while others do not. This may affect our choices for modeling later.

# Correlation within the group

Let's see if any of these inputs are correlated with one another or with the response variable.

```{r}
df %>%
  select(
    starts_with("xn"), 
    response_log
  ) %>%
  cor() %>%
  corrplot::corrplot(type = "upper")
```

The figure shows that some variables are somewhat correlated (e.g. 2 and 6, 5 and 7, 5 and 8). We might consider removing variables with high correlation during freeform modeling. As with some of the other lexicons, no variable is super-strongly correlated with the response.

# Relationship to target variables

## The continuous `response` variable

Note that I log-transformed response since that's what I'll be predicting anyway.

```{r}
df %>%
  pivot_longer(cols = starts_with("xn")) %>%
  ggplot(mapping = aes(x = value, y = response_log)) +
  geom_point() +
  geom_smooth(formula = y ~ x, method = "loess") + 
  facet_wrap(~ name, scales = "free")
```

Like the other lexicons, the loess lines are nearly (but not exactly) linear. Based on this figure and the corresponding ones for other groups, I'm interested in using splines to model them.


## The `outcome` classification target

```{r}
df %>%
  select(-response_log) %>%
  pivot_longer(cols = starts_with("xn")) %>%
  ggplot(mapping = aes(x = value, y = outcome_numeric)) +
  geom_point(size = 4, alpha = .33) +
  facet_wrap(~ name, scales = "free")
```

Of all of the predictor groups evaluated so far, this one has the strongest separation between events and non-events, with lower values of each predictor seeming to correlate with the event occurring. This may suggest that we want to lean on the NRC lexicon during classification modeling.